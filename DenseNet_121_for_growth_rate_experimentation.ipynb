{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet 121 - for growth rate experimentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klvntagoe/DesneNets/blob/master/DenseNet_121_for_growth_rate_experimentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0-i46z0qGX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This cell imports the drive library and mounts your Google Drive as a VM local drive. \n",
        "# You can access to your Drive files using this path “/content/gdrive/My Drive/”\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na-iw8dxQ6WI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time, copy, os\n",
        "import torchvision.transforms as transforms\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3drUEIKQ9Ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CUDA for PyTorch\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
        "\n",
        "\n",
        "model_name = \"densenet\"\n",
        "num_classes = 10            #CIFAR10\n",
        "batch_size = 64\n",
        "epochs = 20\n",
        "learning_rate = 0.1\n",
        "gr_to_experiment = 8\n",
        "gr = gr_to_experiment\n",
        "pretrained = False           #When False, we train a model from scratch, when True we initialize weights to be a pretrained model on ImageNet\n",
        "feature_extract = False     #When False, we finetune the whole model, when True we only update the reshaped layer params\n",
        "\n",
        "#NOTE feature_extract IS FALSE RN\n",
        "#REMEMBER TO CHANGE RESULTS FILE NAME WHEN CHANGING EXPERIMENTATION VALUES\n",
        "data_dir = \"./data\"\n",
        "save = './gdrive/My Drive/results_growth_rate=' + str(gr) + '_from_scratch.csv'\n",
        "model_location =  \"./gdrive/My Drive/denseNet121_gr=\"+ str(gr) + \"_from_scratch.dat\"\n",
        "\n",
        "print('DenseNet 121 for CIFAR10:')\n",
        "print('batch size = ' + str(batch_size))\n",
        "print('Epochs = ' + str(epochs))\n",
        "print('Learning rate = ' + str(learning_rate))\n",
        "print('Growth rate = ' + str(gr))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNmXG18Ofj8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#COPIED FROM THE TORCH VISION IMPLEMENTATION - https://pytorch.org/docs/0.4.0/_modules/torchvision/models/densenet.html\n",
        "\n",
        "from torchvision.models import DenseNet\n",
        "\n",
        "def densenet121(pretrained=False, **kwargs):\n",
        "    \"\"\"Densenet-121 model from\n",
        "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
        "\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = DenseNet(num_init_features=64, growth_rate=gr, block_config=(6, 12, 24, 16),\n",
        "                     **kwargs)\n",
        "    if pretrained:\n",
        "        # '.'s are no longer allowed in module names, but pervious _DenseLayer\n",
        "        # has keys 'norm.1', 'relu.1', 'conv.1', 'norm.2', 'relu.2', 'conv.2'.\n",
        "        # They are also in the checkpoints in model_urls. This pattern is used\n",
        "        # to find such keys.\n",
        "        pattern = re.compile(\n",
        "            r'^(.*denselayer\\d+\\.(?:norm|relu|conv))\\.((?:[12])\\.(?:weight|bias|running_mean|running_var))$')\n",
        "        state_dict = model_zoo.load_url(model_urls['densenet121'])\n",
        "        for key in list(state_dict.keys()):\n",
        "            res = pattern.match(key)\n",
        "            if res:\n",
        "                new_key = res.group(1) + res.group(2)\n",
        "                state_dict[new_key] = state_dict[key]\n",
        "                del state_dict[key]\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxO1g3-RQ-n_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "def initialize_model(num_classes, feature_extract, use_pretrained):\n",
        "    model_ft = densenet121(pretrained=use_pretrained)\n",
        "    set_parameter_requires_grad(model_ft, feature_extract)\n",
        "    num_ftrs = model_ft.classifier.in_features\n",
        "    model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "    input_size = 224\n",
        "    return model_ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj1-nVpGF5tY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grs = [32, 16, 8, 4, 2, 1]\n",
        "for e in grs:\n",
        "  gr = e\n",
        "  model = initialize_model(num_classes, feature_extract, pretrained)\n",
        "  model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "  params = sum([np.prod(p.size()) for p in model_parameters])\n",
        "  print(params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilO5R295RABe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#INITIALIZE MODEL\n",
        "gr = gr_to_experiment\n",
        "model_ft = initialize_model(num_classes, feature_extract, pretrained)\n",
        "\n",
        "\n",
        "\n",
        "#GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.device_count() > 0:\n",
        "  print(torch.cuda.device_count(), \"GPUs available\")\n",
        "  model_ft = nn.DataParallel(model_ft)\n",
        "model_ft.to(device)\n",
        "\n",
        "\n",
        "\n",
        "#LOAD DATA\n",
        "transform = transforms.Compose(\n",
        "    [transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))]\n",
        "    )\n",
        "trainset = torchvision.datasets.CIFAR10(root=data_dir, train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.CIFAR10(root=data_dir, train=False, download=False, transform=transform)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "\n",
        "\n",
        "#OPTIMIZATION\n",
        "params_to_update = model_ft.parameters()\n",
        "\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            print(\"\\t\",name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qek-gLmSRCbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TRAINING\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params_to_update,lr=learning_rate)\n",
        "\n",
        "# Start log\n",
        "with open(save, 'w') as f:\n",
        "  f.write('epoch,train_loss,valid_loss,validation_accuracy,\\n')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    i = 0     #Peace of mind\n",
        "    j = 0     #Peace of mind\n",
        "    for images,labels in train_loader:\n",
        "        if use_cuda:\n",
        "            images, labels = images.cuda(), labels.cuda()\n",
        "        train = Variable(images.view(-1,3,224,224))\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model_ft(train)\n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if (i % 100 == 0): print(i)\n",
        "        i+=1\n",
        "        \n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "\n",
        "        with torch.no_grad(): #Turning off gradients to speed up\n",
        "            model_ft.eval()\n",
        "            for images,labels in test_loader:\n",
        "                if use_cuda:\n",
        "                    images, labels = images.cuda(), labels.cuda()\n",
        "                test = Variable(images.view(-1,3,224,224))\n",
        "                labels = Variable(labels)\n",
        "                \n",
        "                log_ps = model_ft(test)\n",
        "                test_loss += criterion(log_ps,labels)\n",
        "            \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim = 1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "                \n",
        "                if (j % 100 == 0):print(j)\n",
        "                j+=1\n",
        "        model_ft.train() \n",
        "        \n",
        "        train_l = running_loss/len(train_loader)\n",
        "        test_l = test_loss/len(test_loader)\n",
        "        acc = accuracy/len(test_loader)\n",
        "        \n",
        "        # Print results\n",
        "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
        "            \"Training Loss: {:.3f}.. \".format(train_l),\n",
        "            \"Test Loss: {:.3f}.. \".format(test_l),\n",
        "            \"Test Accuracy: {:.3f}\".format(acc)\n",
        "             )\n",
        "        \n",
        "        # Log results\n",
        "        with open(save, 'a') as f:\n",
        "          f.write('%03d,%0.6f,%0.6f,%0.5f,\\n' % (\n",
        "                (epoch + 1),\n",
        "                train_l,\n",
        "                test_l,\n",
        "                acc,\n",
        "            ))\n",
        "        \n",
        "        #Save results\n",
        "        torch.save(model_ft.state_dict(), model_location)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}